{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install google-cloud-bigquery\n",
    "!pip install google-cloud-storage\n",
    "!pip install pandas-gbq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado lo que queremos conseguir es tratar los datos para que se los podamos pasar al modelo, tanto para entrentarlo como para clasificar neuvos elementos posteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer tres tratamientos de datos distintos que depende del tipo de clasificación que queremos obtener: mensaje de cookies, aceptar cookies y cerrar cookies.\n",
    "\n",
    "Una vez sabemos que datos vamos a querer tener para nuestro modelaje, los crearemos y los guardaremos como objetos pickle para el posterior modelaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mensaje de cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente los mensajes de cookies siempre son del tipo (name en nuestros datos) div, span, td o p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "credentials_file = 'tfmfabri-2cf8db9433ba.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_file\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Query sin limitar (todos los datos)\n",
    "query = 'SELECT label,text,url FROM tfm.tfm_url_df where name in (\"div\",\"p\",\"span\",\"td\") and text is not null and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\"' \n",
    "\n",
    "# Query sin limitada (solo 100000 filas)\n",
    "#query = 'SELECT label,text,url FROM tfm.tfm_url_df where name in (\"div\",\"p\",\"span\",\"td\") and text is not null and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" LIMIT 100000' \n",
    "\n",
    "df = pd.read_gbq(query,project_id='tfmfabri')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos caracteres especiales por medios de expresiones regulares\n",
    "import re\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(\"[≡!@#$≡<>+%*()'-]|\\n|\\t\", ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos los espacios en blanco duplicados\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(' +', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la longitud del texto\n",
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las filas que no tengan texto\n",
    "df = df[df['text_length'] != 0]\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos hemos descargado 100000 filas de nuestra base de datos, sin embargo, para poder saber con certeza como son nuestros elementos \"mensaje_cookies\" vamos a descargarnos todos y los vamos a guardar en el dataframe df_m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT label,text,url FROM tfm.tfm_url_df where name in (\"div\",\"p\",\"span\",\"td\") and text is not null and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" and label = \"mensaje_cookies\"' \n",
    "\n",
    "df_m = pd.read_gbq(query,project_id='tfmfabri')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la longitud del texto de los mensajes de cookies\n",
    "df_m['text_length'] = df_m['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los distintos valores que toma el campo \"text_length\"\n",
    "df_m['text_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas de nuestro dataframe de datos (df) donde la lontiud del texto sea un 25% \n",
    "# mayor que el máximo de la longitud del texto de los mensajes de cookies\n",
    "\n",
    "max_cookie_message_length = df_m['text_length'].max() * 1.25\n",
    "df = df[(df['text_length'] < max_cookie_message_length) & (df['text_length'] > 2)]\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos los duplicados\n",
    "df = df.sort_values(by=['label'],ascending=False).drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos los datasets test y train para entrenar y testar el modelo\n",
    "Debido a la gran discrepancia en el número de datos dependiendo de si es mensaje cookies o si no lo es, vamos a filtrar y vamos a pasarle al modelo un número similar de cada tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['label','text']]\n",
    "df_message = df[df['label'] == 'mensaje_cookies']\n",
    "df_message_train = df_message.sample(frac=0.8)\n",
    "df_message_test = pd.concat([df_message, df_message_train]).drop_duplicates(keep=False)\n",
    "\n",
    "df_other = df[df['label'] == '0'].sample(frac=0.01) #Dejo solo el 10%\n",
    "df_other_train = df_other.sample(frac=0.8)\n",
    "df_other_test = pd.concat([df_other, df_other_train]).drop_duplicates(keep=False)\n",
    "\n",
    "df_train = pd.concat([df_message_train,df_other_train])\n",
    "df_test = pd.concat([df_message_test,df_other_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de mensajes de cookies en train\n",
    "len(df_message_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de datos no mensaje de cookies en test\n",
    "len(df_message_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de datos totales en train\n",
    "len(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de datos totales en test\n",
    "len(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un pickle\n",
    "import pickle\n",
    "\n",
    "with open('df_message_train.pkl', 'wb') as f:\n",
    "    pickle.dump(df_train, f)\n",
    "    \n",
    "with open('df_message_test.pkl', 'wb') as f:\n",
    "    pickle.dump(df_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aceptar cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente los mensajes de cookies siempre son del tipo (name en nuestros datos) div, span, td o p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "credentials_file = 'tfmfabri-2cf8db9433ba.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_file\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Query sin limitar (todos los datos)\n",
    "query = 'SELECT * FROM tfm.tfm_url_df where name in (\"a\",\"b\",\"button\",\"div\",\"label\",\"span\",\"strong\",\"td\",\"p\") and width_height not like \"%None%\" and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" and position_x_y != \"(0, 0)\"' \n",
    "\n",
    "# Query sin limitada (solo 100000 filas)\n",
    "#query = 'SELECT * FROM tfm.tfm_url_df where name in (\"a\",\"b\",\"button\",\"div\",\"label\",\"span\",\"strong\",\"td\",\"p\") and width_height not like \"%None%\" and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" and position_x_y != \"(0, 0)\" LIMIT 100000' \n",
    "\n",
    "df = pd.read_gbq(query,project_id='tfmfabri')\n",
    "\n",
    "\n",
    "df.loc[~df['label'].isin(['aceptar_cookies','mensaje_cookies']),'label'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los campos que vamos a introducir a nuestro modelo clasificador de aceptar cookies los vamos a calcular por URL, esto es debido a que hay campos que se calculan con respecto al elemento \"mensaje de cookies\" que es único y distinto para cada página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaramos las funciones que vamos a utilizar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "\n",
    "# Función que dada una fila coge su posición x y su ancho y calcula la nueva coordenada x que será más real\n",
    "# pues estará en el centro del elemento\n",
    "def new_x(x):\n",
    "    return x['position_x'] + x['width']/2\n",
    "\n",
    "# Función que dada una fila coge su posición y y su alto y calcula la nueva coordenada y que será más real\n",
    "# pues estará en el centro del elemento\n",
    "def new_y(y):\n",
    "    return y['position_y'] + y['height']/2\n",
    "\n",
    "# Calula la distancia entre dos puntos. Objetivo: calcular la distancia entre el elemento y el elemento\n",
    "# \"mensaje cookies\"\n",
    "# La funcion tiene como argumentos: una fila del dataframe de donde sacaremos las coordenadas y la coordenada\n",
    "# x e y del elemento \"mensaje cookies\"\n",
    "\n",
    "def calculate_distance(x,cm_x,cm_y):\n",
    "    return math.sqrt((x['position_x'] - cm_x)**2 + (x['position_y'] - cm_y)**2)\n",
    "\n",
    "# Listado de palabras con las que vamos a hacer un one hot encoding. Son las palabras que más están presentes\n",
    "# en los botones de aceptar cookies.\n",
    "\n",
    "word_list = {\n",
    "'de',\n",
    "'política',\n",
    "'y',\n",
    "'a',\n",
    "'en',\n",
    "'cookies',\n",
    "'más',\n",
    "'la',\n",
    "'ver',\n",
    "'al',\n",
    "'información',\n",
    "'que',\n",
    "'aceptar',\n",
    "'ok',\n",
    "'acepto',\n",
    "'cookies',\n",
    "'de',\n",
    "'continuar',\n",
    "'estoy',\n",
    "'acuerdo',\n",
    "'entendido',\n",
    "'navegando',\n",
    "'seguir'\n",
    "}\n",
    "\n",
    "# Función a la que se le pasa un elemento, se coge el texto y se crea una matriz one hot encoding.\n",
    "def is_in_one_hot(x):\n",
    "\n",
    "    text = x['text'].lower().strip()\n",
    "    text = re.sub(' +', ' ',text)\n",
    "    text = text.split()\n",
    "    if len(text) < 7:\n",
    "        for t in text:\n",
    "            if t in word_list:\n",
    "                x[t] = 1\n",
    "    return x\n",
    "\n",
    "# Función que calcula la distancia al padre común mas cercano de dos elementos HTML\n",
    "def get_parent_distance(s_cm, s_el):\n",
    "\n",
    "   \n",
    "    s_cm = s_cm[0].split(\">\")\n",
    "    s_cm = [w.strip() for w in s_cm]\n",
    "    s_cm_len = len(s_cm)\n",
    "    \n",
    "    s_el = s_el.split(\">\")\n",
    "    s_el = [w.strip() for w in s_el]   \n",
    "    s_el_len = len(s_el)\n",
    "    \n",
    "    count_parent = 0\n",
    "\n",
    "    if s_cm_len > s_el_len:\n",
    "        smaller = min(s_cm_len,s_el_len)\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]\n",
    "        count_parent = s_cm_len - s_el_len\n",
    "    else:\n",
    "        smaller = min(s_cm_len,s_el_len)\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]\n",
    "        \n",
    "    count = smaller\n",
    "\n",
    "    while s_cm != s_el:\n",
    "        count_parent += 1\n",
    "        smaller -= 1\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]        \n",
    "\n",
    "    return count_parent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicamos las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame()\n",
    "\n",
    "unique_url = df['url'].unique()\n",
    "\n",
    "\n",
    "for url in unique_url:\n",
    "    df_u = df[df['url'] == url]\n",
    "    if df_u.count()[0] == 0:\n",
    "        continue\n",
    "    if df_u[df_u['label'] == 'mensaje_cookies'].count()[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    df_u['text'] = df_u['text'].apply(lambda x: re.sub(\"[≡!@#$≡<>+%*()'-]|\\n|\\t\", ' ', str(x)))\n",
    "    df_u['text'] = df_u['text'].apply(lambda x: re.sub(' +', ' ',x))\n",
    "    df_u['text_length'] = df_u['text'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    df_u['position_x_y'] = df_u['position_x_y'].apply(lambda x: x.replace(\"(\",\"\"))\n",
    "    df_u['position_x_y'] = df_u['position_x_y'].apply(lambda x: x.replace(\")\",\"\"))\n",
    "    df_u['position_x'] = df_u['position_x_y'].apply(lambda x: x.split(\",\")[0])\n",
    "    df_u['position_x'] = df_u['position_x'].astype(float)\n",
    "    df_u['position_y'] = df_u['position_x_y'].apply(lambda x: x.split(\",\")[1])\n",
    "    df_u['position_y'] = df_u['position_y'].astype(float)\n",
    "    df_u['width_height'] = df_u['width_height'].apply(lambda x: x.replace(\"(\",\"\"))\n",
    "    df_u['width_height'] = df_u['width_height'].apply(lambda x: x.replace(\")\",\"\"))\n",
    "    df_u['width'] = df_u['width_height'].apply(lambda x: x.split(\",\")[0])\n",
    "    df_u['width'] = df_u['width'].astype(float)\n",
    "    df_u['height'] = df_u['width_height'].apply(lambda x: x.split(\",\")[1])\n",
    "    df_u['height'] = df_u['height'].astype(float)\n",
    "    df_u['position_x'] = df_u.apply(lambda x: new_x(x) , axis=1)\n",
    "    df_u['position_y'] = df_u.apply(lambda x: new_y(x) , axis=1)\n",
    "\n",
    "    cm_y = df_u['position_y'][df_u['label'] == 'mensaje_cookies'].values[0]\n",
    "    cm_x = df_u['position_x'][df_u['label'] == 'mensaje_cookies'].values[0]\n",
    "\n",
    "    df_u['distance_cm'] = df_u.apply(lambda x: calculate_distance(x,cm_x,cm_y),axis=1)\n",
    "    df_f = pd.concat([df_f,df_u])\n",
    "\n",
    "# Los siguientes cálculos los hacemos con el dataframe entero, pero antes comprobamos que no está vacío.\n",
    "if len(df_f.index) > 0:\n",
    "    \n",
    "    # Seleccionamos las columnas que queremos del dataframe principal (df_f) y las guardamos en df_d\n",
    "    df_d = df_f[['css_selector','url','label','text_length','width','height','distance_cm','text','name']]\n",
    "    \n",
    "    # Aplicamos one hot enconding al texto\n",
    "    df_d = df_d.apply(lambda x: is_in_one_hot(x),axis=1)\n",
    "    \n",
    "    # Calculamos la mínima distancia al elemento HTML padre común entre el elemento a probar y el elemento de mensaje de cookies.\n",
    "    # Este cálculo lo volvemos a hacer por URl\n",
    "    df_d['parent_distance'] = 0\n",
    "    for url in df_d['url'].unique():\n",
    "        df_url = df_d[df_d['url'] == url]\n",
    "        cm = df_d[df_d['url'] == url][df_d['label'] == 'mensaje_cookies']\n",
    "        cm_css_selector = cm['css_selector'].values\n",
    "        df_url['parent_distance'] = df_url['css_selector'].apply(lambda x: get_parent_distance(cm_css_selector,x))\n",
    "        df_d[df_d['url'] == url] = df_url\n",
    "    \n",
    "    df_d = df_d.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "columns_to_normalize = ['text_length','width','height','distance_cm','parent_distance']\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    df_d[col]=(df_d[col]-df_d[col].min())/(df_d[col].max()-df_d[col].min())\n",
    "    #df_d[col]=(df_d[col]-df_d[col].mean())/df_d[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d[df_d['label'].isin(['aceptar_cookies'])].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = df_d.copy()\n",
    "\n",
    "df_tt[df_tt['name'] == 'a']['name'] = None\n",
    "\n",
    "# Hacemos get dummies para crear las columnas one hot encoding de los atributos name de los elementos\n",
    "df_tt = pd.get_dummies(df_tt, columns=['name'])\n",
    "\n",
    "# Quitamos las columnas que no necesitamos\n",
    "df_tt.drop('css_selector',axis=1, inplace=True)\n",
    "df_tt.drop('url',axis=1, inplace=True)\n",
    "df_tt.drop('text',axis=1, inplace=True)\n",
    "\n",
    "# Seleccionamos un parte de los elementos que están categorizados como \"aceptar_cookies\"\n",
    "df_tt_ok = df_tt[df_tt['label'].isin(['aceptar_cookies'])]\n",
    "df_tt_ok_test = df_tt_ok.sample(frac=0.2)\n",
    "df_tt_ok_train = pd.concat([df_tt_ok, df_tt_ok_test]).drop_duplicates(keep=False)\n",
    "\n",
    "# Seleccionamos una parte de los elementos que no son \"aceptar_cookies\"\n",
    "# Aquí dividimos en dos partes, para entrenar bien a nuestro modelo, le metemos elementos de cualquier sitio\n",
    "# de la página y elemento que están cercanos al \"mensaje_cookies\" así le enseñamos a saber que \n",
    "# no por estar cerca es un elemento del tipo \"aceptar_cookies\"\n",
    "df_tt_ko = df_tt[~df_tt['label'].isin(['aceptar_cookies'])]\n",
    "df_tt_ko_near = df_tt_ko[df_tt_ko['parent_distance'] < 0.17].sample(frac=0.010)\n",
    "df_tt_ko_far = df_tt_ko[df_tt_ko['parent_distance'] >= 0.17].sample(frac=0.003)\n",
    "\n",
    "\n",
    "\n",
    "df_tt_ko = pd.concat([df_tt_ko_near, df_tt_ko_far]).sample(frac=0.6)\n",
    "\n",
    "\n",
    "\n",
    "df_tt_ko_test = df_tt_ko.sample(frac=0.2)\n",
    "df_tt_ko_train = pd.concat([df_tt_ko, df_tt_ko_test]).drop_duplicates(keep=False)\n",
    "\n",
    "\n",
    "df_tt_test = pd.concat([df_tt_ok_test,df_tt_ko_test])\n",
    "df_tt_test_label = df_tt_test.copy()['label']\n",
    "df_tt_test.drop('label',axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_tt_train = pd.concat([df_tt_ok_train,df_tt_ko_train])\n",
    "df_tt_train_label = df_tt_train.copy()['label']\n",
    "df_tt_train.drop('label',axis=1, inplace=True)\n",
    "\n",
    "df_tt_total = pd.concat([df_tt_ok,df_tt_ko.sample(frac=0.001)])\n",
    "df_tt_total_label = df_tt_total.copy()['label']\n",
    "df_tt_total.drop('label',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un pickle\n",
    "import pickle\n",
    "\n",
    "with open('df_aceptar_train.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_train, f)\n",
    "    \n",
    "with open('df_aceptar_test.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_test, f)\n",
    "    \n",
    "with open('df_aceptar_train_label.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_train_label, f)\n",
    "    \n",
    "with open('df_aceptar_test_label.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_test_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cerrar cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente los mensajes de cookies siempre son del tipo (name en nuestros datos) div, span, td o p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "credentials_file = 'tfmfabri-2cf8db9433ba.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_file\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Query sin limitar (todos los datos)\n",
    "query = 'SELECT * FROM tfm.tfm_url_df where name in (\"a\",\"b\",\"button\",\"div\",\"label\",\"span\",\"strong\",\"td\",\"p\") and width_height not like \"%None%\" and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" and position_x_y != \"(0, 0)\"' \n",
    "\n",
    "# Query sin limitada (solo 100000 filas)\n",
    "#query = 'SELECT * FROM tfm.tfm_url_df where name in (\"a\",\"b\",\"button\",\"div\",\"label\",\"span\",\"strong\",\"td\",\"p\") and width_height not like \"%None%\" and is_in_head = false and is_script = false and is_no_script = false and width_height != \"(0, 0)\" and position_x_y != \"(0, 0)\" LIMIT 100000' \n",
    "\n",
    "df = pd.read_gbq(query,project_id='tfmfabri')\n",
    "\n",
    "\n",
    "df.loc[~df['label'].isin(['cerrar_cookies','mensaje_cookies']),'label'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los campos que vamos a introducir a nuestro modelo clasificador de cerrar cookies los vamos a calcular por URL, esto es debido a que hay campos que se calculan con respecto al elemento \"mensaje de cookies\" que es único y distinto para cada página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaramos las funciones que vamos a utilizar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "\n",
    "# Función que dada una fila coge su posición x y su ancho y calcula la nueva coordenada x que será más real\n",
    "# pues estará en el centro del elemento\n",
    "def new_x(x):\n",
    "    return x['position_x'] + x['width']/2\n",
    "\n",
    "# Función que dada una fila coge su posición y y su alto y calcula la nueva coordenada y que será más real\n",
    "# pues estará en el centro del elemento\n",
    "def new_y(y):\n",
    "    return y['position_y'] + y['height']/2\n",
    "\n",
    "# Calula la distancia entre dos puntos. Objetivo: calcular la distancia entre el elemento y el elemento\n",
    "# \"mensaje cookies\"\n",
    "# La funcion tiene como argumentos: una fila del dataframe de donde sacaremos las coordenadas y la coordenada\n",
    "# x e y del elemento \"mensaje cookies\"\n",
    "\n",
    "def calculate_distance(x,cm_x,cm_y):\n",
    "    return math.sqrt((x['position_x'] - cm_x)**2 + (x['position_y'] - cm_y)**2)\n",
    "\n",
    "# Listado de palabras con las que vamos a hacer un one hot encoding. Son las palabras que más están presentes\n",
    "# en los botones.\n",
    "\n",
    "word_list = {\n",
    "'de',\n",
    "'política',\n",
    "'y',\n",
    "'a',\n",
    "'en',\n",
    "'cookies',\n",
    "'más',\n",
    "'la',\n",
    "'ver',\n",
    "'al',\n",
    "'información',\n",
    "'que',\n",
    "'aceptar',\n",
    "'ok',\n",
    "'acepto',\n",
    "'cookies',\n",
    "'de',\n",
    "'continuar',\n",
    "'estoy',\n",
    "'acuerdo',\n",
    "'entendido',\n",
    "'navegando',\n",
    "'seguir'\n",
    "}\n",
    "\n",
    "# Función a la que se le pasa un elemento, se coge el texto y se crea una matriz one hot encoding.\n",
    "def is_in_one_hot(x):\n",
    "\n",
    "    text = x['text'].lower().strip()\n",
    "    text = re.sub(' +', ' ',text)\n",
    "    text = text.split()\n",
    "    if len(text) < 7:\n",
    "        for t in text:\n",
    "            if t in word_list:\n",
    "                x[t] = 1\n",
    "    return x\n",
    "\n",
    "# Función que calcula la distancia al padre común mas cercano de dos elementos HTML\n",
    "def get_parent_distance(s_cm, s_el):\n",
    "\n",
    "   \n",
    "    s_cm = s_cm[0].split(\">\")\n",
    "    s_cm = [w.strip() for w in s_cm]\n",
    "    s_cm_len = len(s_cm)\n",
    "    \n",
    "    s_el = s_el.split(\">\")\n",
    "    s_el = [w.strip() for w in s_el]   \n",
    "    s_el_len = len(s_el)\n",
    "    \n",
    "    count_parent = 0\n",
    "\n",
    "    if s_cm_len > s_el_len:\n",
    "        smaller = min(s_cm_len,s_el_len)\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]\n",
    "        count_parent = s_cm_len - s_el_len\n",
    "    else:\n",
    "        smaller = min(s_cm_len,s_el_len)\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]\n",
    "        \n",
    "    count = smaller\n",
    "\n",
    "    while s_cm != s_el:\n",
    "        count_parent += 1\n",
    "        smaller -= 1\n",
    "        s_cm = s_cm[:smaller]\n",
    "        s_el = s_el[:smaller]        \n",
    "\n",
    "    return count_parent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicamos las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame()\n",
    "\n",
    "unique_url = df['url'].unique()\n",
    "\n",
    "\n",
    "for url in unique_url:\n",
    "    df_u = df[df['url'] == url]\n",
    "    if df_u.count()[0] == 0:\n",
    "        continue\n",
    "    if df_u[df_u['label'] == 'mensaje_cookies'].count()[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    df_u['text'] = df_u['text'].apply(lambda x: re.sub(\"[≡!@#$≡<>+%*()'-]|\\n|\\t\", ' ', str(x)))\n",
    "    df_u['text'] = df_u['text'].apply(lambda x: re.sub(' +', ' ',x))\n",
    "    df_u['text_length'] = df_u['text'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    df_u['position_x_y'] = df_u['position_x_y'].apply(lambda x: x.replace(\"(\",\"\"))\n",
    "    df_u['position_x_y'] = df_u['position_x_y'].apply(lambda x: x.replace(\")\",\"\"))\n",
    "    df_u['position_x'] = df_u['position_x_y'].apply(lambda x: x.split(\",\")[0])\n",
    "    df_u['position_x'] = df_u['position_x'].astype(float)\n",
    "    df_u['position_y'] = df_u['position_x_y'].apply(lambda x: x.split(\",\")[1])\n",
    "    df_u['position_y'] = df_u['position_y'].astype(float)\n",
    "    df_u['width_height'] = df_u['width_height'].apply(lambda x: x.replace(\"(\",\"\"))\n",
    "    df_u['width_height'] = df_u['width_height'].apply(lambda x: x.replace(\")\",\"\"))\n",
    "    df_u['width'] = df_u['width_height'].apply(lambda x: x.split(\",\")[0])\n",
    "    df_u['width'] = df_u['width'].astype(float)\n",
    "    df_u['height'] = df_u['width_height'].apply(lambda x: x.split(\",\")[1])\n",
    "    df_u['height'] = df_u['height'].astype(float)\n",
    "    df_u['position_x'] = df_u.apply(lambda x: new_x(x) , axis=1)\n",
    "    df_u['position_y'] = df_u.apply(lambda x: new_y(x) , axis=1)\n",
    "\n",
    "    cm_y = df_u['position_y'][df_u['label'] == 'mensaje_cookies'].values[0]\n",
    "    cm_x = df_u['position_x'][df_u['label'] == 'mensaje_cookies'].values[0]\n",
    "\n",
    "    df_u['distance_cm'] = df_u.apply(lambda x: calculate_distance(x,cm_x,cm_y),axis=1)\n",
    "    df_f = pd.concat([df_f,df_u])\n",
    "\n",
    "# Los siguientes cálculos los hacemos con el dataframe entero, pero antes comprobamos que no está vacío.\n",
    "if len(df_f.index) > 0:\n",
    "    \n",
    "    # Seleccionamos las columnas que queremos del dataframe principal (df_f) y las guardamos en df_d\n",
    "    df_d = df_f[['css_selector','url','label','text_length','width','height','distance_cm','text','name']]\n",
    "    \n",
    "    # Aplicamos one hot enconding al texto\n",
    "    df_d = df_d.apply(lambda x: is_in_one_hot(x),axis=1)\n",
    "    \n",
    "    # Calculamos la mínima distancia al elemento HTML padre común entre el elemento a probar y el elemento de mensaje de cookies.\n",
    "    # Este cálculo lo volvemos a hacer por URl\n",
    "    df_d['parent_distance'] = 0\n",
    "    for url in df_d['url'].unique():\n",
    "        df_url = df_d[df_d['url'] == url]\n",
    "        cm = df_d[df_d['url'] == url][df_d['label'] == 'mensaje_cookies']\n",
    "        cm_css_selector = cm['css_selector'].values\n",
    "        df_url['parent_distance'] = df_url['css_selector'].apply(lambda x: get_parent_distance(cm_css_selector,x))\n",
    "        df_d[df_d['url'] == url] = df_url\n",
    "    \n",
    "    df_d = df_d.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "columns_to_normalize = ['text_length','width','height','distance_cm','parent_distance']\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    df_d[col]=(df_d[col]-df_d[col].min())/(df_d[col].max()-df_d[col].min())\n",
    "    #df_d[col]=(df_d[col]-df_d[col].mean())/df_d[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d[df_d['label'].isin(['cerrar_cookies'])].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = df_d.copy()\n",
    "\n",
    "df_tt[df_tt['name'] == 'a']['name'] = None\n",
    "\n",
    "# Hacemos get dummies para crear las columnas one hot encoding de los atributos name de los elementos\n",
    "df_tt = pd.get_dummies(df_tt, columns=['name'])\n",
    "\n",
    "# Quitamos las columnas que no necesitamos\n",
    "df_tt.drop('css_selector',axis=1, inplace=True)\n",
    "df_tt.drop('url',axis=1, inplace=True)\n",
    "df_tt.drop('text',axis=1, inplace=True)\n",
    "\n",
    "# Seleccionamos un parte de los elementos que están categorizados como \"cerrar_cookies\"\n",
    "df_tt_ok = df_tt[df_tt['label'].isin(['cerrar_cookies'])]\n",
    "df_tt_ok_test = df_tt_ok.sample(frac=0.2)\n",
    "df_tt_ok_train = pd.concat([df_tt_ok, df_tt_ok_test]).drop_duplicates(keep=False)\n",
    "\n",
    "# Seleccionamos una parte de los elementos que no son \"cerrar_cookies\"\n",
    "# Aquí dividimos en dos partes, para entrenar bien a nuestro modelo, le metemos elementos de cualquier sitio\n",
    "# de la página y elemento que están cercanos al \"mensaje_cookies\" así le enseñamos a saber que \n",
    "# no por estar cerca es un elemento del tipo \"cerrar_cookies\"\n",
    "df_tt_ko = df_tt[~df_tt['label'].isin(['cerrar_cookies'])]\n",
    "df_tt_ko_near = df_tt_ko[df_tt_ko['parent_distance'] < 0.17].sample(frac=0.010)\n",
    "df_tt_ko_far = df_tt_ko[df_tt_ko['parent_distance'] >= 0.17].sample(frac=0.003)\n",
    "\n",
    "\n",
    "\n",
    "df_tt_ko = pd.concat([df_tt_ko_near, df_tt_ko_far]).sample(frac=0.6)\n",
    "\n",
    "\n",
    "\n",
    "df_tt_ko_test = df_tt_ko.sample(frac=0.2)\n",
    "df_tt_ko_train = pd.concat([df_tt_ko, df_tt_ko_test]).drop_duplicates(keep=False)\n",
    "\n",
    "\n",
    "df_tt_test = pd.concat([df_tt_ok_test,df_tt_ko_test])\n",
    "df_tt_test_label = df_tt_test.copy()['label']\n",
    "df_tt_test.drop('label',axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_tt_train = pd.concat([df_tt_ok_train,df_tt_ko_train])\n",
    "df_tt_train_label = df_tt_train.copy()['label']\n",
    "df_tt_train.drop('label',axis=1, inplace=True)\n",
    "\n",
    "df_tt_total = pd.concat([df_tt_ok,df_tt_ko.sample(frac=0.001)])\n",
    "df_tt_total_label = df_tt_total.copy()['label']\n",
    "df_tt_total.drop('label',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un pickle\n",
    "import pickle\n",
    "\n",
    "with open('df_cerrar_train.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_train, f)\n",
    "    \n",
    "with open('df_cerrar_test.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_test, f)\n",
    "    \n",
    "with open('df_cerrar_train_label.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_train_label, f)\n",
    "    \n",
    "with open('df_cerrar_test_label.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tt_test_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
